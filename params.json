{"name":"Hemi","tagline":"Portable CUDA C/C++","body":"Hemi: Simpler, More Portable CUDA C++\r\n=====================================\r\n\r\n[<img align=\"right\" src=\"https://raw.github.com/harrism/hemi/master/hemi-logo-transparent.png\" width=\"272\" height=\"152\"/>](https://raw.github.com/harrism/hemi/master/hemi-logo.png)\r\nHemi simplifies writing portable CUDA C/C++ code. With Hemi, \r\n\r\n - you can write parallel kernels like you write for loops—in line in your CPU code—and run them on your GPU;\r\n - you can easily write code that compiles and runs either on the CPU or GPU;\r\n - you can easily launch C++ Lambda functions as GPU kernels;\r\n - kernel launch configuration details like thread block size and grid size are optimization details, rather than requirements.\r\n\r\nWith Hemi, parallel code for the GPU can be as simple as the `parallel_for` loop in the following code, which can also be compiled and run on the CPU.\r\n\r\n```\r\nvoid saxpy(int n, float a, const float *x, float *y)\r\n{\r\n  hemi::parallel_for(0, n, [=] HEMI_LAMBDA (int i) {\r\n      y[i] = a * x[i] + y[i];\r\n  }); \r\n}\r\n```\r\n\r\nCurrent Version\r\n---------------\r\n\r\nThis is version: 2.0 (HEMI_VERSION == 200000)\r\n\r\nHemi on github\r\n--------------\r\n\r\nThe home for Hemi is https://github.com/harrism/hemi, where you can find the latest changes and information.\r\n\r\nBlog Posts\r\n----------\r\nRead about Hemi 2 on the [NVIDIA Parallel Forall Blog](http://devblogs.nvidia.com/parallelforall/simple-portable-parallel-c-hemi-2/). [An older post about Hemi 1.0](http://devblogs.nvidia.com/parallelforall/developing-portable-cuda-cc-code-hemi/).\r\n\r\nRequirements\r\n------------\r\n\r\nHemi 2 requires a host compiler with support for C++11 or later. For CUDA device execution, Hemi requires CUDA 7.0 or later. To launch lambda expressions on the GPU using `hemi::launch()` or `hemi::parallel_for()`, Hemi requires CUDA 7.5 or later with experimental support for \"extended lambdas\" (enabled using the `nvcc` command line option `--expt-extended-lambda`).\r\n\r\nFeatures\r\n========\r\n\r\nGPU Lambdas and Parallel For\r\n----------------------------\r\n\r\nCUDA 7.5 provides an experimental feature, \"GPU Lambdas\", which enables C++11 Lambda functions with `__device__` annotation to be defined in host code and passed to kernels running on the device. Hemi 2 leverages this feature to provide the `hemi::parallel_for` function which, when compiled for the GPU, launches a parallel kernel which executes the provided GPU lambda function as the body of a parallel loop. When compiled for the CPU, the lambda is executed as the body of a sequential CPU loop. This makes parallel functions nearly as easy to write as a for loop, as the following code shows:\r\n\r\n    parallel_for(0, 100, [] HEMI_LAMBDA (int i) { \r\n        printf(\"%d\\n\", i); \r\n    });\r\n\r\nGPU Lambdas can also be launched directly on the GPU using `hemi::launch`:\r\n\r\n    hemi::launch([=] HEMI_LAMBDA() {\r\n        printf(\"Hello World from Lambda in thread %d of %d\\n\",\r\n            hemi::globalThreadIndex(),\r\n            hemi::globalThreadCount());\r\n    });\r\n\r\nTo launch lambda expressions on the GPU using `hemi::launch()` or `hemi::parallel_for()`, Hemi requires [CUDA 7.5](http://developer.nvidia.com/cuda-toolkit) or later with experimental support for \"extended lambdas\" (enabled using the `nvcc` command line option `--expt-extended-lambda`).\r\n\r\nPortable Parallel Execution\r\n---------------------------\r\n\r\n`hemi::launch` can also be used to portably launch function objects (or *functors*), which are objects of classes that define an `operator()` member. To be launched on the GPU, the `operator()` should be declared with `HEMI_DEV_CALLABLE_MEMBER`. To make this easy, Hemi 2 provides the convenience macro `HEMI_KERNEL_FUNCTION()`. The simple example `hello.cpp` demonstrates its use:\r\n\r\n    HEMI_KERNEL_FUNCTION(hello) {\r\n      printf(\"Hello World from thread %d of %d\\n\",\r\n             hemi::globalThreadIndex(),\r\n             hemi::globalThreadCount());\r\n    }\r\n    \r\n    int main(void) {\r\n      hello hi;\r\n      hemi::launch(hi);          // launch on the GPU\r\n      hemi::deviceSynchronize(); // make sure print flushes before exit\r\n    \r\n      hi();                      // call on CPU\r\n      return 0;\r\n    }\r\n\r\nAs you can see, `HEMI_KERNEL_FUNCTION()` actually defines a functor which must be instantiated. Once instantiated, it can either be launched on the GPU or called from the CPU.\r\n\r\nYou can define portable CUDA kernel functions using `HEMI_LAUNCHABLE`, which defines the function using CUDA `__global__` when compiled using `nvcc`, or as a normal host function otherwise. Launch these functions portably using `hemi::cudaLaunch()`. The example `hello_global.cu` demonstrates:\r\n\r\n    HEMI_LAUNCHABLE void hello() { \r\n      printf(\"Hello World from thread %d of %d\\n\", \r\n             hemi::globalThreadIndex(),\r\n             hemi::globalThreadCount());\r\n    }\r\n    \r\n    int main(void) {\r\n      hemi::cudaLaunch(hello);\r\n      hemi::deviceSynchronize(); // make sure print flushes before exit\r\n      return 0;\r\n    }\r\n\r\nAutomatic Execution Configuration\r\n---------------------------------\r\n\r\nIn both of the examples in the previous section, the execution configuration (the number of thread blocks and size of each block) is automatically decided by Hemi based on the GPU it is running on.  In general, when compiled for the GPU, `hemi::launch()`, `hemi::cudaLaunch()` and `hemi::parallel_for()` will choose a grid configuration that occupies all multiprocessors (SMs) on the GPU.\r\n\r\nAutomatic Execution Configuration is flexible, though. You can explicitly specify the entire execution configuration---grid size, thread block size, and dynamic shared memory allocation---or you can partially specify the execution configuration. For example, you might need to specify just the thread block size. Hemi makes it easy to take full control when you need it for performance tuning, but when you are getting started parallelizing your code, or for functions where ultimate performance is not crucial, you can just let Hemi configure the parallelism for you.\r\n\r\nAs an example, the `nbody_vec4` example provides an optimized version of its main kernel that tiles data in CUDA shared memory. For this, it needs to specify the block size and shared memory allocation explicitly.\r\n\r\n    const int blockSize = 256;\r\n    hemi::ExecutionPolicy ep;\r\n    ep.setBlockSize(blockSize);\r\n    ep.setSharedMemBytes(blockSize * sizeof(Vec4f));\r\n    hemi::cudaLaunch(ep, allPairsForcesShared, forceVectors, bodies, N);\r\n\r\nHowever, note that the number of blocks in the grid is left to Hemi to choose at run time.\r\n\r\nSimple Grid-Stride Loops\r\n----------------------\r\n\r\nA common design pattern in writing scalable, portable parallel CUDA kernels is to use [grid-stride loops](http://devblogs.nvidia.com/parallelforall/cuda-pro-tip-write-flexible-kernels-grid-stride-loops/). Grid-stride loops let you decouple the size of your CUDA grid from the data size it is processing, resulting in less coupling between your host and device code. This also has portability and debugging benefits. \r\n\r\nHemi 2 includes a [grid-stride range](http://devblogs.nvidia.com/parallelforall/power-cpp11-cuda-7/) helper, `grid_stride_range()`, which makes it trivial to use C++11 range-based for loops to iterate in parallel. `grid_stride_range()` can be used in traditional CUDA kernels, such as the following `saxpy` kernel, or it can be combined with other Hemi portability features (in fact it is used in the implementation of `hemi::parallel_for()`).\r\n\r\n    __global__\r\n    void saxpy(int n, float a, float *x, float *y)\r\n    {\r\n      for (auto i : grid_stride_range(0, n)) {\r\n        y[i] = a * x[i] + y[i];\r\n      }\r\n    }\r\n\r\nhemi/hemi.h\r\n-----------\r\n\r\nThe `hemi.h` header provides simple macros that are useful for reusing code between CUDA C/C++ and C/C++ written for other platforms (e.g. CPUs). \r\n\r\nThe macros are used to decorate function prototypes and variable declarations so that they can be compiled by either NVCC or a host compiler (for example gcc or cl.exe, the MS Visual Studio compiler). \r\n \r\nThe macros can be used within .cu, .cuh, .cpp, .h, and .inl files to define code that can be compiled either for the host (e.g., CPU) or the device (e.g., GPU). \r\n\r\nhemi/array.h\r\n------------\r\n\r\nOne of the biggest challenges in writing portable CUDA code is memory management. HEMI provides the `hemi::Array` C++ template class as a simple data management wrapper which allows arrays of arbitrary type to be created and used with both host and device code. hemi::Array maintains a host and a device pointer for each array. It lazily transfers data between the host and device as needed when the user requests a pointer to the host or device memory. Pointer requests specify read-only, read/write, or write-only options so that valid flags can be maintained and data is only copied when the requested pointer is invalid.\r\n\r\nFor example, here is an excerpt from the nbody_vec4 example.\r\n\r\n    hemi::Array<Vec4f> bodies(N, true);\r\n    hemi::Array<Vec4f> forceVectors(N, true);\r\n      \t\r\n    randomizeBodies(bodies.writeOnlyHostPtr(), N);\r\n    \r\n    // Call host function defined in a .cpp compilation unit\r\n    allPairsForcesHost(forceVectors.writeOnlyHostPtr(), bodies.\r\n                       readOnlyHostPtr(), N);\r\n    printf(\"CPU: Force vector 0: (%0.3f, %0.3f, %0.3f)\\n\", \r\n           forceVectors.readOnlyHostPtr()[0].x, \r\n           forceVectors.readOnlyHostPtr()[0].y, \r\n           forceVectors.readOnlyHostPtr()[0].z);\r\n    \r\n      \t...\r\n    \r\n    // Call device function defined in a .cu compilation unit\r\n    // that uses host/device shared functions and class member functions\r\n    allPairsForcesCuda(forceVectors.writeOnlyDevicePtr(), \r\n                       bodies.readOnlyDevicePtr(), N, false);\r\n    \r\n    printf(\"GPU: Force vector 0: (%0.3f, %0.3f, %0.3f)\\n\", \r\n           forceVectors.readOnlyHostPtr()[0].x, \r\n           forceVectors.readOnlyHostPtr()[0].y, \r\n           forceVectors.readOnlyHostPtr()[0].z);\r\n\r\nTypical CUDA code requires explicit duplication of host allocations on the device,and explicit copy calls between them. `hemi::Array` allows CUDA code to be used without writing a single `cudaMalloc`, `cudaFree`, or `cudaMemcpy`. `hemi::Array` supports pinned host memory for efficient PCI-express transfers, and handles CUDA error checking internally.\r\n\r\nPortable Functions\r\n------------------\r\n\r\nA common use for host-device code sharing is commonly used utility functions. For example, if we wish to define an inline function to compute the average of two floats that can be called either from host code or device code, and can be compiled by either the host compiler or NVCC, we define it like this:\r\n\r\n    HEMI_DEV_CALLABLE_INLINE float avgf(float x, float y) { \r\n      return (x+y)/2.0f; \r\n    }\r\n\r\nThe macro definition ensures that when compiled by NVCC, both a host and device version of the function are generated, and a normal inline function is generated when compiled by the host compiler.\r\n\r\nFor example use, see the `CND()` function in the \"blackscholes\" example, as well as several other functions used in the examples.\r\n\r\nPortable Classes\r\n----------------\r\n\r\nThe `HEMI_DEV_CALLABLE_MEMBER` and `HEMI_DEV_CALLABLE_INLINE_MEMBER` macros can be used to create classes that are reusable between host and device code, by decorating any member function prototype that will be used by both device and host code. Here is an example excerpt of a portable class (a 4D vector type used in the \"nbody_vec4\" example).\r\n\r\n    struct HEMI_ALIGN(16) Vec4f\r\n    {\r\n      float x, y, z, w;\r\n    \r\n      HEMI_DEV_CALLABLE_INLINE_MEMBER\r\n      Vec4f() {};\r\n    \r\n      HEMI_DEV_CALLABLE_INLINE_MEMBER\r\n      Vec4f(float xx, float yy, float zz, float ww) : x(xx), y(yy), z(zz), w(ww) {}\r\n    \r\n      HEMI_DEV_CALLABLE_INLINE_MEMBER\r\n      Vec4f(const Vec4f& v) : x(v.x), y(v.y), z(v.z), w(v.w) {}\r\n    \r\n      HEMI_DEV_CALLABLE_INLINE_MEMBER\r\n      Vec4f& operator=(const Vec4f& v) {\r\n        x = v.x; y = v.y; z = v.z; w = v.w;\r\n        return *this;\r\n      }\r\n    \r\n      HEMI_DEV_CALLABLE_INLINE_MEMBER\r\n      Vec4f operator+(const Vec4f& v) const {\r\n        return Vec4f(x+v.x, y+v.y, z+v.z, w+v.w);\r\n      }\r\n      ...\r\n    };\r\n\r\nThe `HEMI_ALIGN` macro is used on types that will be passed in arrays or pointers as arguments to CUDA device kernel functions, to ensure proper alignment. `HEMI_ALIGN` generates correct alignment specifiers for the host compilers, too. For details on alignment, see the NVIDIA CUDA C Programming Guide (Section 5.3 in v5.0).\r\n\r\nPortable Kernels (Legacy Interface)\r\n-----------------------------------\r\n\r\n**`HEMI_KERNEL` and `HEMI_KERNEL_LAUNCH` are the Hemi 1.x interface for defining portable kernels. `HEMI_LAUNCHABLE`\r\n`HEMI_KERNEL` can be used to declare a function that is launchable as a CUDA kernel when compiled with NVCC, or as a C/C++ (host) function when compiled with the host compiler. `HEMI_KERNEL_LAUNCH` is a convenience macro that can be used to launch a kernel function on the device when compiled with NVCC, or call the host function when compiled with the host compiler. \r\n\r\nFor example, here is an excerpt from the \"blackscholes\" example.\r\n\r\n    // Black-Scholes formula for both call and put\r\n    HEMI_KERNEL(BlackScholes)\r\n        (float *callResult, float *putResult, const float *stockPrice,\r\n         const float *optionStrike, const float *optionYears, float Riskfree,\r\n         float Volatility, int optN)\r\n    {\r\n      ...\r\n    }\r\n    \r\n    .... in main() ...\r\n    HEMI_KERNEL_LAUNCH(BlackScholes, gridDim, blockDim, 0, 0,\r\n                       d_callResult, d_putResult, d_stockPrice, d_optionStrike, \r\n                       d_optionYears, RISKFREE, VOLATILITY, OPT_N);\r\n\r\n`HEMI_KERNEL_NAME` can also be used to access the generated name of the kernel function, for example to pass a function pointer to CUDA api functions like `cudaFuncGetAttributes()`.\r\n\r\n`HEMI_KERNEL_LAUNCH` requires grid and block dimensions to be passed to it, but these parameters are ignored when compiled for the host. When`DEBUG` is defined, `HEMI_KERNEL_LAUNCH` checks for CUDA launch and runtime errors.\r\n\r\nPortable Constants\r\n------------------\r\n\r\nGlobal constant values can be defined using the `HEMI_DEFINE_CONSTANT` macro, which takes a name and an initial value. When compiled with NVCC as CUDA code, this declares two versions of the constant, one `__constant__` variable for the device, and one normal host variable. When compiled with a host compiler, only the host variable is defined.\r\n\r\nFor static or external linkage, use the `HEMI_DEFINE_STATIC_CONSTANT` and `HEMI_DEFINE_EXTERN_CONSTANT` versions of the macro, respectively.\r\n\r\nTo access variables defined using `HEMI_DEFINE_*_CONSTANT` macros, use the `HEMI_CONSTANT` macro which automatically resolves to either the device or host constant depending on whether it is called from device or host code. This means that the proper variable will chosen when the constant is accessed within functions declared with `HEMI_DEV_CALLABLE_*` and `HEMI_KERNEL` macros.\r\n\r\nTo explicitly access the device version of a constant, use `HEMI_DEV_CONSTANT`. This is useful when the constant is an argument to a CUDA API function such as `cudaMemcpyToSymbol`, as shown in the following code from the \"nbody_vec4\" example.\r\n\r\n    cudaMemcpyToSymbol(HEMI_DEV_CONSTANT(softeningSquared), \r\n                       &ss, sizeof(float), 0, cudaMemcpyHostToDevice)\r\n\r\nNote: Non-Inline Functions and Methods\r\n--------------------------------------\r\n\r\nThere are non-inline versions of the macros (`HEMI_DEV_CALLABLE` and `HEMI_DEV_CALLABLE_MEMBER`. Take care to avoid multiple definition linker errors due to using these in headers that are included into multiple compilation units. The best way to use `HEMI_DEV_CALLABLE` is to declare functions using this macro in a header, and define their implementation in a .cu file, and compile it with NVCC. This will generate code for both host and device. The host code will be linked into your library or application and callable from other host code compilation units (.c and .cpp files).  \r\n\r\nLikewise, for `HEMI_DEV_CALLABLE_MEMBER`, put the class and function declaration in a header, and the member function implementations in a .cu file, compiled by NVCC.\r\n\r\nNote: Device-Specific Code\r\n-----------------------------\r\n\r\nNote: Code in functions like this must be portable. In other words it must be able to compile and run for both the host or device. If it is not, within the function you can use `HEMI_DEV_CODE` to define separate code for host and device. Example:\r\n\r\n    HEMI_DEV_CALLABLE_INLINE_MEMBER\r\n    float inverseLength(float softening = 0.0f) const {\r\n    #ifdef HEMI_DEV_CODE\r\n      return rsqrtf(lengthSqr() + softening); // use fast GPU intrinsic\r\n    #else\r\n      return 1.0f / sqrtf(lengthSqr() + softening);\r\n    #endif\r\n    }\r\n\r\nUtility Functions\r\n=================\r\n\r\nCUDA Error Checking\r\n-------------------\r\n\r\nhemi.h provides two convenience functions for checking CUDA errors. `checkCuda` verifies that its single argument has the value `cudaSuccess`, and otherwise prints an error message and asserts if #DEBUG is defined. This function is typically wrapped around CUDA \r\nAPI calls, for example:\r\n\r\n    checkCuda(cudaMemcpy(d_stockPrice, stockPrice, OPT_SZ,\r\n                         cudaMemcpyHostToDevice) );\r\n\r\n`checkCudaErrors` takes no arguments and checks the current state of the CUDA context for errors. This function synchronizes the CUDA device (`cudaDeviceSynchronize()`) to ensure asynchronous launch errors are caught.\r\n\r\nBoth `checkCuda` and `checkCudaErrors` act as No-ops when DEBUG is not defined (i.e. release builds).\r\n\r\nIteration\r\n---------\r\n\r\nFor kernel functions with simple independent element-wise parallelism, `hemi/device_api.h` provides functions to enable iterating over elements sequentially in host code or in parallel in device code. \r\n\r\n - `globalThreadIndex()` returns the offset of the current thread within the 1D grid, or zero for host code. In device code, it resolves to `blockDim.x * blockIdx.x + threadIdx.x`.\r\n - `globalThreadCount()` returns the size of the 1D grid in threads, or one in host code. In device code, it resolves to `gridDim.x * blockDim.x`.\r\n\r\nHere's a SAXPY implementation using the above functions.\r\n\r\n    HEMI_LAUNCHABLE\r\n    void saxpy(int n, float a, float *x, float *y)\r\n    {\r\n      using namespace hemi;\r\n      for (int i = globalThreadIndex(); i < n; i += globalThreadCount()) {\r\n        y[i] = a * x[i] + y[i];\r\n      }\r\n    }\r\n\r\nNote it's simpler to use a range-based for loop using `grid_stride_range()` as shown previously.\r\n\r\nThis code can be compiled and run as a sequential function on the host or as a CUDA kernel for the device.\r\n\r\nHemi provides a complete set of portable element accessors in `hemi\\device_api.h` including `localThreadIndex()`, `globalBlockCount()`, etc.\r\n\r\nNote: the `globalThreadIndex()`, `globalThreadCount()`, etc. functions are specialized to simple (but common) element-wise parallelism. As such, they may not be useful for arbitrary strides, data sharing, or other more complex parallelism arrangements, but they may serve as examples for creating your own.\r\n\r\nMix and Match\r\n=============\r\n\r\nHEMI is intended to provide a loosely-coupled set of utilities and examples for creating reusable, portable CUDA C/C++ code. Feel free to use the parts that you need and ignore others. You may modify and replace portions as needed. We have selected a permissive open source license to encourage these kinds of flexible use.\r\n\r\nIf you make changes that you feel would be generally useful, please fork the project on github, commit your changes, and submit a pull request. \r\n\r\nhttps://github.com/harrism/hemi\r\n\r\n\r\nLicense and Copyright\r\n=====================\r\n\r\nCopyright 2012-2015, NVIDIA Corporation\r\n\r\nLicensed under the BSD License. Please see the LICENSE file included with the HEMI source code.","google":"UA-37853718-1","note":"Don't delete this file! It's used internally to help with page regeneration."}